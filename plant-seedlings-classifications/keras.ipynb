{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "tf.Session(config=config)\n",
    "\n",
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import optimizers\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing.image import *\n",
    "from keras.backend import tf as ktf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import os\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4750 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'train',\n",
    "        target_size=(224, 224),\n",
    "        class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4750, 224, 224, 3), (4750, 12), (794, 224, 224, 3))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.load('data/preprocessed/X_train.npy')\n",
    "Y_train = np.load('data/preprocessed/Y_train.npy')\n",
    "X_test = np.load('data/preprocessed/X_test.npy')\n",
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1,)\n",
    "    plt.plot(epochs, acc)\n",
    "    plt.plot(epochs, val_acc)\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.title(' accuracy')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    plt.plot(epochs, loss)\n",
    "    plt.plot(epochs, val_loss)\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.title('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seqModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(224, 224, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(12))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnnmodel = seqModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3800 samples, validate on 950 samples\n",
      "Epoch 1/20\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 1.8302 - acc: 0.3705 - val_loss: 11.3567 - val_acc: 0.0305\n",
      "Epoch 2/20\n",
      "3800/3800 [==============================] - 26s 7ms/step - loss: 1.0903 - acc: 0.6437 - val_loss: 11.1574 - val_acc: 0.0337\n",
      "Epoch 3/20\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.8409 - acc: 0.7303 - val_loss: 15.1315 - val_acc: 0.0442\n",
      "Epoch 4/20\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.6590 - acc: 0.7839 - val_loss: 15.1831 - val_acc: 0.0411: 0s - loss: 0.6590 - acc:\n",
      "Epoch 5/20\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.5612 - acc: 0.8168 - val_loss: 15.2082 - val_acc: 0.0442\n",
      "Epoch 6/20\n",
      "3800/3800 [==============================] - 28s 7ms/step - loss: 0.4828 - acc: 0.8418 - val_loss: 15.1921 - val_acc: 0.0453\n",
      "Epoch 7/20\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.4427 - acc: 0.8632 - val_loss: 15.2069 - val_acc: 0.0411\n",
      "Epoch 8/20\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.3991 - acc: 0.8816 - val_loss: 15.2580 - val_acc: 0.0368\n",
      "Epoch 9/20\n",
      "3800/3800 [==============================] - 27s 7ms/step - loss: 0.3659 - acc: 0.8876 - val_loss: 15.2017 - val_acc: 0.0484\n",
      "Epoch 10/20\n",
      "3800/3800 [==============================] - 26s 7ms/step - loss: 0.3605 - acc: 0.8932 - val_loss: 15.2006 - val_acc: 0.0474\n",
      "Epoch 11/20\n",
      "3800/3800 [==============================] - 26s 7ms/step - loss: 0.3064 - acc: 0.9150 - val_loss: 15.2326 - val_acc: 0.0421\n",
      "Epoch 12/20\n",
      "3800/3800 [==============================] - 26s 7ms/step - loss: 0.3312 - acc: 0.9111 - val_loss: 15.2767 - val_acc: 0.0411\n",
      "Epoch 00012: early stopping\n"
     ]
    }
   ],
   "source": [
    "cnnmodel_history = cnnmodel.fit(X_train, Y_train, batch_size=5, epochs=20, validation_split=0.2,\n",
    "             callbacks=[EarlyStopping(monitor='val_acc', patience=3, verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inception_model = InceptionV3(input_tensor=Input((224, 224, 3)), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750/4750 [==============================] - 31s 7ms/step\n",
      "794/794 [==============================] - 5s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "inc_train_bf = inception_model.predict(X_train, verbose=1)\n",
    "inc_test_bf = inception_model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_model(input_shape):\n",
    "    input_img = Input(input_shape)\n",
    "    X = GlobalAveragePooling2D()(input_img)\n",
    "#     X = Flatten(input_shape=input_shape)(input_img)\n",
    "    X = Dropout(0.5)(X)   \n",
    "    \n",
    "    X = Dense(1024, activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "        \n",
    "    X = Dense(1024, activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "        \n",
    "    X = Dense(1024, activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = Dense(12, activation='softmax')(X)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=X)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',#optimizers.SGD(lr=1e-4, momentum=0.9),#'adam',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inctop_model = top_model(inc_train_bf.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3800 samples, validate on 950 samples\n",
      "Epoch 1/20\n",
      "3800/3800 [==============================] - 6s 1ms/step - loss: 7.7893 - acc: 0.1918 - val_loss: 4.5785 - val_acc: 0.0095\n",
      "Epoch 2/20\n",
      "3800/3800 [==============================] - 1s 335us/step - loss: 2.3135 - acc: 0.2495 - val_loss: 3.5075 - val_acc: 0.0126\n",
      "Epoch 3/20\n",
      "3800/3800 [==============================] - 1s 328us/step - loss: 1.8984 - acc: 0.2816 - val_loss: 3.6776 - val_acc: 0.0011\n",
      "Epoch 4/20\n",
      "3800/3800 [==============================] - 1s 326us/step - loss: 1.7929 - acc: 0.3200 - val_loss: 4.2639 - val_acc: 0.0105\n",
      "Epoch 5/20\n",
      "3800/3800 [==============================] - 1s 328us/step - loss: 1.7516 - acc: 0.3221 - val_loss: 4.6062 - val_acc: 0.0189\n",
      "Epoch 6/20\n",
      "3800/3800 [==============================] - 1s 335us/step - loss: 1.6763 - acc: 0.3661 - val_loss: 4.4984 - val_acc: 0.0032\n",
      "Epoch 7/20\n",
      "3800/3800 [==============================] - 1s 342us/step - loss: 1.6182 - acc: 0.3655 - val_loss: 5.2614 - val_acc: 0.0242\n",
      "Epoch 8/20\n",
      "3800/3800 [==============================] - ETA: 0s - loss: 1.5626 - acc: 0.404 - 1s 336us/step - loss: 1.5624 - acc: 0.4047 - val_loss: 5.6244 - val_acc: 0.0084\n",
      "Epoch 9/20\n",
      "3800/3800 [==============================] - 1s 326us/step - loss: 1.5355 - acc: 0.4166 - val_loss: 5.1929 - val_acc: 0.0242\n",
      "Epoch 10/20\n",
      "3800/3800 [==============================] - 1s 327us/step - loss: 1.4979 - acc: 0.4324 - val_loss: 6.0060 - val_acc: 0.0305\n",
      "Epoch 11/20\n",
      "3800/3800 [==============================] - 1s 328us/step - loss: 1.4815 - acc: 0.4384 - val_loss: 6.4167 - val_acc: 0.0221\n",
      "Epoch 12/20\n",
      "3800/3800 [==============================] - 1s 321us/step - loss: 1.4434 - acc: 0.4505 - val_loss: 7.2898 - val_acc: 0.0189\n",
      "Epoch 13/20\n",
      "3800/3800 [==============================] - 1s 329us/step - loss: 1.4477 - acc: 0.4424 - val_loss: 6.7436 - val_acc: 0.0242\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "inc_history = inctop_model.fit(inc_train_bf, Y_train, batch_size=100, epochs=20, validation_split=0.2,\n",
    "             callbacks=[EarlyStopping(monitor='val_acc', patience=3, verbose=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "794/794 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "ind_to_class = {y:x for x,y in train_generator.class_indices.items()}\n",
    "preds = model.predict(X_test, verbose=1, batch_size=5)\n",
    "sub = pd.DataFrame(test)\n",
    "sub['species'] = np.argmax(preds, axis=1)\n",
    "sub['species'] = sub['species'].apply(lambda x: ind_to_class[x])\n",
    "sub.to_csv('sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
