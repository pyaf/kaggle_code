{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "# config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "tf.Session(config=config)\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pipline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_json('data/train.json')\n",
    "train['inc_angle'] = pd.to_numeric(train['inc_angle'], errors='coerce') #133 NqNs\n",
    "train['inc_angle'] = train['inc_angle'].fillna(method='pad');\n",
    "\n",
    "test = pd.read_json('data/test.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['inc_angle'] = pd.to_numeric(train['inc_angle'], errors='coerce') #133 NqNs\n",
    "train['inc_angle'] = train['inc_angle'].fillna(method='pad');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data(df, angles=False, labels=False):\n",
    "    imgs = []\n",
    "    ylabels = []\n",
    "    inc_angles = []\n",
    "    for i, row in df.iterrows():\n",
    "        #make 75x75 image\n",
    "        band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "        band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "        band_3 = band_1 / band_2\n",
    "#         band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "        \n",
    "        # Rescale\n",
    "#         a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "#         b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n",
    "#         c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "        \n",
    "        a = (band_1 + abs(band_1.min())) / np.max((band_1 + abs(band_1.min())))\n",
    "        b = (band_2 + abs(band_2.min())) / np.max((band_2 + abs(band_2.min())))\n",
    "        c = (band_3 + abs(band_3.min())) / np.max((band_3 + abs(band_3.min())))\n",
    "        \n",
    "        imgs.append(np.dstack((a, b, c)))\n",
    "        if labels:\n",
    "            ylabels.append(row['is_iceberg'])\n",
    "        if angles: \n",
    "            inc_angles.append(row['inc_angle'])\n",
    "    if angles and labels:    \n",
    "        return np.array(imgs), np.array(inc_angles), np.array(ylabels)\n",
    "    if labels:\n",
    "        return np.array(imgs), np.array(ylabels)\n",
    "    return np.array(imgs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, inc_angles, Y_train = get_training_data(train, angles=True, labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = get_training_data(test, angles=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,\n",
    "                         channel_shift_range=0,\n",
    "                         zoom_range = 0.2,\n",
    "                         rotation_range = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_flow_for_two_inputs(Xtrain, inc_angles, Ytrain):\n",
    "    g1 = gen.flow(Xtrain, inc_angles, batch_size=10, seed=5)\n",
    "    g2 = gen.flow(Xtrain, Ytrain, batch_size=10, seed=5)\n",
    "    while True:\n",
    "        i = g1.next()\n",
    "        j = g2.next()\n",
    "        yield [i[0], i[1]], j[1]    \n",
    "        \n",
    "# gen_flow_with_inc_angles = gen_flow_for_two_inputs(X_train, inc_angles, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xtrain_data, Ytrain_data = get_training_data(train_data, labels=True)\n",
    "# Xdev_data, Ydev_data = get_training_data(dev_data, labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_gen = gen.flow(X_train, Y_train, seed=5)\n",
    "# dev_gen = gen.flow(Xdev_data, Ydev_data seed=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug = []\n",
    "Y_train_aug = []\n",
    "for i in tqdm(range(1000)):\n",
    "    x, y = train_gen.next()\n",
    "    X_train_aug.extend(x)\n",
    "    Y_train_aug.extend(y)\n",
    "\n",
    "X_train_aug = np.asarray(X_train_aug)\n",
    "Y_train_aug = np.asarray(Y_train_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug.shape, Y_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_data, dev_data = train_test_split(train, test_size=0.1,random_state=0, stratify=train['is_iceberg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.subplot(1, 2, 1,)\n",
    "    plt.plot(epochs, acc)\n",
    "    plt.plot(epochs, val_acc)\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.title(' accuracy')\n",
    "\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    plt.plot(epochs, loss)\n",
    "    plt.plot(epochs, val_loss)\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.title('loss')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### VGG Model with angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def vggModel():\n",
    "    ang_input = Input(shape=[1], name='inc_angle')\n",
    "    x1 = Dense(1)(ang_input)\n",
    "    \n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                         input_shape=(75, 75, 3), classes=1)\n",
    "    x2 = base_model.get_layer('block5_pool').output\n",
    "    x2 = GlobalMaxPooling2D()(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "    X = Concatenate()([x2, x1])\n",
    "    \n",
    "#     X = Dropout(0.2)(X)\n",
    "    X = Dense(1024, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "    X = Dense(512, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "#     X = Dense(256, activation='relu')(X)\n",
    "#     X = Dropout(0.2)(X)\n",
    "    predictions = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs=[base_model.input, ang_input],\n",
    "                outputs=predictions)\n",
    "    \n",
    "    \n",
    "    for layer in model.layers[:19]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=sgd,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = vggModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit_generator(\n",
    "    gen_flow_with_inc_angles,\n",
    "    steps_per_epoch=32,\n",
    "    epochs=30,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(Xdev, Ydev)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "acc = model.evaluate([Xtrain, inc_angles], Ytrain, verbose=1, batch_size=50)\n",
    "print('Train score', acc[0])\n",
    "print('Train accuracy', acc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG model without angle layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vggModel2():\n",
    "\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, \n",
    "                         input_shape=(75, 75, 3), classes=1)\n",
    "    X = base_model.get_layer('block5_pool').output\n",
    "#     X = GlobalMaxPooling2D()(X)\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(256, activation='relu')(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "#     X = Dense(256, activation='relu')(X)\n",
    "#     X = Dropout(0.2)(X)\n",
    "#     X = Dense(256, activation='relu')(X)\n",
    "#     X = Dropout(0.2)(X)\n",
    "    predictions = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs=base_model.input,\n",
    "                outputs=predictions)\n",
    "    \n",
    "    \n",
    "    for layer in model.layers[:19]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    sgd = SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "    print(model.summary())\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=sgd,\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2 = vggModel2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.fit_generator(\n",
    "    gen_flow_without_inc_angles,\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(Xdev, Ydev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = model2.evaluate(Xtrain, Ytrain, verbose=1, batch_size=50)\n",
    "print('Train score', acc[0])\n",
    "print('Train accuracy', acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_ = vggModel2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model2_.fit(Xtrain, Ytrain, batch_size=50, epochs=20, verbose=1, validation_data=(Xdev, Ydev))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN without transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CNN_without_tl():\n",
    "    #Build keras model\n",
    "    \n",
    "    input_img = Input(shape=(75, 75, 3))\n",
    "    \n",
    "    # CNN 1\n",
    "    X = Conv2D(32, kernel_size=(2, 2),activation='relu')(input_img)\n",
    "    \n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    # CNN 2\n",
    "    X = Conv2D(64, kernel_size=(2, 2),activation='relu')(X)\n",
    "    \n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "    # CNN 3\n",
    "    X = Conv2D(128, kernel_size=(2, 2),activation='relu')(X)\n",
    "    \n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "    X = Dropout(0.3)(X)\n",
    "\n",
    "    #CNN 4\n",
    "    X = Conv2D(256, kernel_size=(2, 2),activation='relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "\n",
    "    X = Conv2D(512, kernel_size=(2, 2),activation='relu')(X)\n",
    "    X = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(X)\n",
    "    X = Dropout(0.2)(X)\n",
    "\n",
    "\n",
    "    \n",
    "    # You must flatten the data for the dense layers\n",
    "    X = Flatten()(X)\n",
    "\n",
    "    #Dense 1\n",
    "    X = Dense(1024, activation='relu')(X)\n",
    "#     model.add(BatchNormalization())\n",
    "    X = Dropout(0.5)(X)\n",
    "\n",
    "    #Dense 2\n",
    "    X = Dense(1024, activation='relu')(X)\n",
    "#     model.add(BatchNormalization())\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    X = Dense(1024, activation='relu')(X)\n",
    "#     model.add(BatchNormalization())\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    \n",
    "    X = Dense(512, activation='relu')(X)\n",
    "#     model.add(BatchNormalization())\n",
    "    X = Dropout(0.5)(X)\n",
    "    \n",
    "    \n",
    "    X = Dense(512, activation='relu')(X)\n",
    "#     model.add(BatchNormalization())\n",
    "    X = Dropout(0.5)(X)\n",
    "    # Output \n",
    "    X = Dense(1, activation=\"sigmoid\")(X)\n",
    "\n",
    "#     optimizer = Adam(lr=0.001, decay=0.0)\n",
    "    model = Model(inputs=input_img, outputs=X)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "    \n",
    "#     print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3 = CNN_without_tl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# batch_size = 100\n",
    "# for epoch in range(10):\n",
    "# #     print('epoch', epoch)\n",
    "#     i = 0\n",
    "#     for x_batch, y_batch in gen.flow(X_train, Y_train, batch_size=batch_size):\n",
    "#         model3.fit(x_batch, y_batch, batch_size=batch_size, verbose=0, validation_split=0.2)\n",
    "#         i+=1\n",
    "#         if i > len(X_train) // batch_size:\n",
    "#             print(model3.evaluate(X_train, Y_train, verbose=0, batch_size=50))\n",
    "#             break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model_history3 = model3.fit(X_train_aug, Y_train_aug, batch_size=100, epochs=20, verbose=1, validation_split=0.3,\n",
    "          callbacks=[EarlyStopping(monitor='val_acc', patience=3, verbose=1)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(model_history3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model3.evaluate(X_train_aug, Y_train_aug, verbose=1, batch_size=50)\n",
    "print('Train score', acc[0])\n",
    "print('Train accuracy', acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model4 = CNN_without_tl() #with generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.fit_generator(\n",
    "    gen_flow_without_inc_angles,\n",
    "    steps_per_epoch=100,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_data=(Xdev, Ydev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_model(input_shape):\n",
    "    input_img = Input(input_shape)\n",
    "    X = GlobalAveragePooling2D()(input_img)\n",
    "#     X = Flatten(input_shape=input_shape)(input_img)\n",
    "    X = Dropout(0.2)(X)   \n",
    "    \n",
    "    X = Dense(4096, activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "    X = Dense(4096, activation='relu')(X)\n",
    "    X = Dropout(0.5)(X)\n",
    "#     X = Dense(512, activation='relu')(X)\n",
    "#     X = Dropout(0.5)(X)\n",
    "#     X = Dense(512, activation='relu')(X)\n",
    "#     X = Dropout(0.5)(X)\n",
    "    X = Dense(1, activation='sigmoid')(X)\n",
    "    \n",
    "    model = Model(inputs=input_img, outputs=X)\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                 optimizer='adam',#optimizers.SGD(lr=1e-4, momentum=0.9),#'adam',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inception_model = InceptionV3(input_tensor=Input((75, 75, 3)), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_train_bf = inception_model.predict(X_train_aug, verbose=1)\n",
    "inc_test_bf = inception_model.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Xtrain_data_bf, Xdev_data_bf, Ytrain_data_bf, Ydev_data_bf = train_test_split(inc_train_bf, Y_train, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_gen = gen.flow(Xtrain_data_bf, Ytrain_data_bf, batch_size=10, seed=5)\n",
    "# dev_gen = gen.flow(Xdev_data_bf, Ydev_data_bf, batch_size=10, seed=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bottleneck_features_train = inception_model.predict_generator(train_gen, 1400)#80% of train\n",
    "# bottleneck_features_validation = inception_model.predict_generator(dev_gen, 160)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bottleneck_features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inctop_model = top_model(inc_train_bf.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# model.fit_generator(\n",
    "#     train_gen,\n",
    "#     steps_per_epoch=32,\n",
    "#     epochs=30,\n",
    "#     shuffle=True,\n",
    "#     verbose=1,\n",
    "#     validation_data=(Xdev, Ydev)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_history = inctop_model.fit(inc_train_bf, Y_train_aug, batch_size=100, epochs=20, validation_split=0.1,\n",
    "             callbacks=[EarlyStopping(monitor='val_acc', patience=3, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(inc_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inctop_model.save_weights('models/inctop_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incx = inception_model.predict(X_train, verbose=1)\n",
    "acc = inctop_model.evaluate(incx, Y_train, verbose=1, batch_size=50)\n",
    "print('Train score', acc[0])\n",
    "print('Train accuracy', acc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ft_model(base_model, top_model_weights_path):\n",
    "    \n",
    "    top = top_model(base_model.output_shape[1:])\n",
    "    top.load_weights(top_model_weights_path)\n",
    "#     x = base_model.predict(X_train)\n",
    "#     print(top.evaluate(x, Y_train))\n",
    "    ft_model = Model(inputs=base_model.inputs, outputs=top(base_model.output))\n",
    "    \n",
    "    ft_model.compile(loss='binary_crossentropy',\n",
    "                 optimizer=SGD(lr=1e-4, momentum=0.9),\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    return ft_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inception_model = InceptionV3(input_tensor=Input((75, 75, 3)), weights='imagenet', include_top=False)\n",
    "for layer in inception_model.layers[:299]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inc_ft_model = ft_model(inception_model, 'models/inctop_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_ft_history = inc_ft_model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch=140,\n",
    "    epochs=20,\n",
    "    validation_data=dev_gen,\n",
    "    validation_steps=16,\n",
    "    callbacks=[EarlyStopping(monitor='val_acc', patience=3, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inc_ft_model2 = ft_model(inception_model, 'models/inctop_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc_history2 = inc_ft_model2.fit(X_train, Y_train, batch_size=10, epochs=20, validation_split=0.1,\n",
    "             callbacks=[EarlyStopping(monitor='val_acc', patience=3, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(inc_history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for i, row in test.iterrows():\n",
    "    #make 75x75 image\n",
    "    band_1 = np.array(row['band_1']).reshape(75, 75)\n",
    "    band_2 = np.array(row['band_2']).reshape(75, 75)\n",
    "    band_3 = band_1 + band_2 # plus since log(x*y) = log(x) + log(y)\n",
    "\n",
    "    # Rescale\n",
    "    a = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n",
    "    b = (band_2 - band_2.mean()) / (band_2.max() - band_2.min())\n",
    "    c = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n",
    "\n",
    "    imgs.append(np.dstack((a, b, c)))\n",
    "    \n",
    "Xtest = np.array(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds = inctop_model.predict(inc_test_bf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "submission['is_iceberg']=preds\n",
    "submission.to_csv('sub.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
