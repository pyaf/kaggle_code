{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9dd005d681b15ac8a2247462907143905aa0e656"
   },
   "source": [
    "This is a work in progress notebook... sorry for no comments.\n",
    "\n",
    "It is based on https://www.kaggle.com/jesperdramsch/intro-to-seismic-salt-and-how-to-geophysics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "00833d394e3069216af171fd979c814e7e1e430d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": false,
    "_uuid": "0e26e21ff39e8b2afc0003fec4e4f5269f61aa4c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "im_width = 128\n",
    "im_height = 128\n",
    "border = 5\n",
    "im_chan = 2 # Number of channels: first is original and second cumsum(axis=0)\n",
    "n_features = 1 # Number of extra features, like depth\n",
    "data_folder = '/home/eee/ug/15084015/.kaggle/competitions/tgs-salt-identification-challenge/'\n",
    "path_train = os.path.join(data_folder, 'train')\n",
    "path_test = os.path.join(data_folder, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "89455be399a79910334eb76beafc40bcdab08f83"
   },
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3dc15ce723e9721c6815651bbbd1478a86d2f1c1"
   },
   "outputs": [],
   "source": [
    "df_depths = pd.read_csv(os.path.join(data_folder, 'depths.csv'), index_col='id')\n",
    "df_depths.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e49b3c2436ae2a70776db01748bc0a64a4f47303"
   },
   "outputs": [],
   "source": [
    "df_depths.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71bc5858327bdf6c54a9f99c0ac68e27abfcd567"
   },
   "outputs": [],
   "source": [
    "ids= ['1f1cc6b3a4','5b7c160d0d','6c40978ddf','7dfdf6eeb8','7e5a6e5013']\n",
    "plt.figure(figsize=(30,15))\n",
    "for j, img_name in enumerate(ids):\n",
    "    q = j+1\n",
    "    img = load_img(data_folder + 'train/images/' + img_name + '.png', grayscale=True)\n",
    "    img_mask = load_img(data_folder + 'train/masks/' + img_name + '.png', grayscale=True)\n",
    "    \n",
    "    img = np.array(img)\n",
    "    img_cumsum = (np.float32(img)-img.mean()).cumsum(axis=0)\n",
    "    img_mask = np.array(img_mask)\n",
    "    \n",
    "    plt.subplot(1,3*(1+len(ids)),q*3-2)\n",
    "    plt.imshow(img, cmap='seismic')\n",
    "    plt.subplot(1,3*(1+len(ids)),q*3-1)\n",
    "    plt.imshow(img_cumsum, cmap='seismic')\n",
    "    plt.subplot(1,3*(1+len(ids)),q*3)\n",
    "    plt.imshow(img_mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls '/home/eee/ug/15084015/.kaggle/competitions/tgs-salt-identification-challenge/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "97114b7b4f28347130dc3e44af5469d6efdf7ab1",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ids = next(os.walk(os.path.join(path_train, \"images\")))[2]\n",
    "test_ids = next(os.walk(os.path.join(path_test, \"images\")))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_ids), len(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8f02165966489c8a21bb7127bb88e7cf607599d"
   },
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "X = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.float32)\n",
    "y = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.float32)\n",
    "X_feat = np.zeros((len(train_ids), n_features), dtype=np.float32)\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = path_train\n",
    "    \n",
    "    # Depth\n",
    "    X_feat[n] = df_depths.loc[id_.replace('.png', ''), 'z']\n",
    "    \n",
    "    # Load X\n",
    "    img = load_img(path + '/images/' + id_, grayscale=True)\n",
    "    x_img = img_to_array(img)\n",
    "    x_img = resize(x_img, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    \n",
    "    # Create cumsum x\n",
    "    x_center_mean = x_img[border:-border, border:-border].mean()\n",
    "    x_csum = (np.float32(x_img)-x_center_mean).cumsum(axis=0)\n",
    "    x_csum -= x_csum[border:-border, border:-border].mean()\n",
    "    x_csum /= max(1e-3, x_csum[border:-border, border:-border].std())\n",
    "\n",
    "    # Load Y\n",
    "    mask = img_to_array(load_img(path + '/masks/' + id_, grayscale=True))\n",
    "    mask = resize(mask, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "\n",
    "    # Save images\n",
    "    X[n, ..., 0] = x_img.squeeze() / 255\n",
    "    X[n, ..., 1] = x_csum.squeeze()\n",
    "    y[n] = mask / 255\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f48688422d75bf806210071c5e06d8b7ea7fc1d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split train and valid\n",
    "X_train, X_valid, X_feat_train, X_feat_valid, y_train, y_valid = train_test_split(X, X_feat, y, test_size=0.15, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fc85395b2e67e5af02de30d5ca90924b6aa89490",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize X_feat\n",
    "x_feat_mean = X_feat_train.mean(axis=0, keepdims=True)\n",
    "x_feat_std = X_feat_train.std(axis=0, keepdims=True)\n",
    "X_feat_train -= x_feat_mean\n",
    "X_feat_train /= x_feat_std\n",
    "\n",
    "X_feat_valid -= x_feat_mean\n",
    "X_feat_valid /= x_feat_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "faf6ea42655fb0f5ee8994a65a7c3bef888ef1ae",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(X_train))\n",
    "\n",
    "has_mask = y_train[ix].max() > 0\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "ax[0].imshow(X_train[ix, ..., 0], cmap='seismic', interpolation='bilinear')\n",
    "if has_mask:\n",
    "    ax[0].contour(y_train[ix].squeeze(), colors='k', levels=[0.5])\n",
    "ax[0].set_title('Seismic')\n",
    "\n",
    "ax[1].imshow(X_train[ix, ..., 1], cmap='seismic', interpolation='bilinear')\n",
    "if has_mask:\n",
    "    ax[1].contour(y_train[ix].squeeze(), colors='k', levels=[0.5])\n",
    "ax[1].set_title('Seismic cumsum')\n",
    "\n",
    "ax[2].imshow(y_train[ix].squeeze(), interpolation='bilinear', cmap='gray')\n",
    "ax[2].set_title('Salt');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0d66a11a8d8d48e16640307185062f5494c1f5b6"
   },
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4716a2112dfb71c75e60bff90cb17836f78bf66",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define IoU metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58e87797db5bb02b8f0ad6a0af6592e94f9f8b3f"
   },
   "outputs": [],
   "source": [
    "# Build U-Net model\n",
    "input_img = Input((im_height, im_width, im_chan), name='img')\n",
    "input_features = Input((n_features, ), name='feat')\n",
    "\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (input_img)\n",
    "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
    "p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
    "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
    "p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
    "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
    "p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
    "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
    "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "# Join features information in the depthest layer\n",
    "f_repeat = RepeatVector(8*8)(input_features)\n",
    "f_conv = Reshape((8, 8, n_features))(f_repeat)\n",
    "p4_feat = concatenate([p4, f_conv], -1)\n",
    "\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4_feat)\n",
    "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
    "\n",
    "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "u6 = concatenate([u6, c4])\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
    "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
    "\n",
    "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "u7 = concatenate([u7, c3])\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
    "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
    "\n",
    "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "u8 = concatenate([u8, c2])\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
    "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
    "\n",
    "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "u9 = concatenate([u9, c1], axis=3)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
    "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
    "\n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "model = Model(inputs=[input_img, input_features], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy') #, metrics=[mean_iou]) # The mean_iou metrics seens to leak train and test values...\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58969e2e3bdca3b94da4ebd4e513a83455adf00a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=5, verbose=1),\n",
    "    ReduceLROnPlateau(patience=3, verbose=1),\n",
    "    ModelCheckpoint('model-tgs-salt-1.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "results = model.fit({'img': X_train, 'feat': X_feat_train}, y_train, batch_size=16, epochs=50, callbacks=callbacks,\n",
    "                    validation_data=({'img': X_valid, 'feat': X_feat_valid}, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5ab8516fb8ab135872dd4f4b895b5d76206df1fa"
   },
   "source": [
    "# Test Data\n",
    "First we'll get the test data. This takes a while, it's 18000 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c6d376a5ed9fa0ff708299f55a0a8ed8b8471137",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get and resize test images\n",
    "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.float32)\n",
    "X_feat_test = np.zeros((len(test_ids), n_features), dtype=np.float32)\n",
    "sizes_test = []\n",
    "print('Getting and resizing test images ... ')\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm_notebook(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = path_test\n",
    "    \n",
    "    # Depth\n",
    "    X_feat_test[n] = df_depths.loc[id_.replace('.png', ''), 'z']\n",
    "    \n",
    "    # Load X\n",
    "    img = load_img(path + '/images/' + id_, grayscale=True)\n",
    "    x = img_to_array(img)\n",
    "    sizes_test.append([x.shape[0], x.shape[1]])\n",
    "    x = resize(x, (128, 128, 1), mode='constant', preserve_range=True)\n",
    "    \n",
    "    # Create cumsum x\n",
    "    x_center_mean = x[border:-border, border:-border].mean()\n",
    "    x_csum = (np.float32(x)-x_center_mean).cumsum(axis=0)\n",
    "    x_csum -= x_csum[border:-border, border:-border].mean()\n",
    "    x_csum /= max(1e-3, x_csum[border:-border, border:-border].std())\n",
    "\n",
    "    # Save images\n",
    "    X_test[n, ..., 0] = x.squeeze() / 255\n",
    "    X_test[n, ..., 1] = x_csum.squeeze()\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b91882163bfbba8cd7ccc343215be754611daf53",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize X_test_feats\n",
    "X_feat_test -= x_feat_mean\n",
    "X_feat_test /= x_feat_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bfaa7456bf2a9c2a763995ebf67af85a1655b4b5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_weights('model-tgs-salt-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7afac10b8ab977fbbbe06bd0845de2eb3d80a5da",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Evaluate on validation set (this must be equals to the best log_loss)\n",
    "model.evaluate({'img': X_valid, 'feat': X_feat_valid}, y_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2316034edcb7227673fd9b69264ca9c0d0e87f14",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "preds_train = model.predict({'img': X_train, 'feat': X_feat_train}, verbose=1)\n",
    "preds_val = model.predict({'img': X_valid, 'feat': X_feat_valid}, verbose=1)\n",
    "preds_test = model.predict({'img': X_test, 'feat': X_feat_test}, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "af64790cdb7e5beb05fc34635cdf092124d7dc20",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create list of upsampled test masks\n",
    "preds_test_upsampled = []\n",
    "for i in tnrange(len(preds_test)):\n",
    "    preds_test_upsampled.append(resize(np.squeeze(preds_test[i]), \n",
    "                                       (sizes_test[i][0], sizes_test[i][1]), \n",
    "                                       mode='constant', preserve_range=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7da5a47444df98205dd7039223868b5d67f15400",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_test_upsampled[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "24defa25c00d0d91b38e559515e78c63f4d26e2b"
   },
   "source": [
    "We'll look at it again, just to be sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "246229afabb0a35b99c7af54d7e2f757968535a4",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds):\n",
    "    ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='seismic')\n",
    "    if has_mask:\n",
    "        ax[0].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[0].set_title('Seismic')\n",
    "\n",
    "    ax[1].imshow(X[ix, ..., 1], cmap='seismic')\n",
    "    if has_mask:\n",
    "        ax[1].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[1].set_title('Seismic cumsum')\n",
    "\n",
    "    ax[2].imshow(y[ix].squeeze())\n",
    "    ax[2].set_title('Salt')\n",
    "\n",
    "    ax[3].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[3].contour(y[ix].squeeze(), colors='k', levels=[0.5])\n",
    "    ax[3].set_title('Salt Pred');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6302c46fc76d8a43cb87d01c43c60c3c8f0ac98b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "plot_sample(X_train, y_train, preds_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "43bedd865f0139a9899b9b9e413874190200123a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check if valid data looks all right\n",
    "plot_sample(X_valid, y_valid, preds_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "676d58a476b89c74187d2269bec8db5fb7d1bd96"
   },
   "source": [
    "# Threshold optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c0aa5d0d6c2a7d508d0ab5b2c1fec1fead77e786",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
    "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
    "    labels = y_true_in\n",
    "    y_pred = y_pred_in\n",
    "    \n",
    "    true_objects = 2\n",
    "    pred_objects = 2\n",
    "\n",
    "    intersection = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))[0]\n",
    "\n",
    "    # Compute areas (needed for finding the union between all objects)\n",
    "    area_true = np.histogram(labels, bins = true_objects)[0]\n",
    "    area_pred = np.histogram(y_pred, bins = pred_objects)[0]\n",
    "    area_true = np.expand_dims(area_true, -1)\n",
    "    area_pred = np.expand_dims(area_pred, 0)\n",
    "\n",
    "    # Compute union\n",
    "    union = area_true + area_pred - intersection\n",
    "\n",
    "    # Exclude background from the analysis\n",
    "    intersection = intersection[1:,1:]\n",
    "    union = union[1:,1:]\n",
    "    union[union == 0] = 1e-9\n",
    "\n",
    "    # Compute the intersection over union\n",
    "    iou = intersection / union\n",
    "\n",
    "    # Precision helper function\n",
    "    def precision_at(threshold, iou):\n",
    "        matches = iou > threshold\n",
    "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
    "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
    "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
    "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
    "        return tp, fp, fn\n",
    "\n",
    "    # Loop over IoU thresholds\n",
    "    prec = []\n",
    "    if print_table:\n",
    "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        tp, fp, fn = precision_at(t, iou)\n",
    "        if (tp + fp + fn) > 0:\n",
    "            p = tp / (tp + fp + fn)\n",
    "        else:\n",
    "            p = 0\n",
    "        if print_table:\n",
    "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
    "        prec.append(p)\n",
    "    \n",
    "    if print_table:\n",
    "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
    "    return np.mean(prec)\n",
    "\n",
    "def iou_metric_batch(y_true_in, y_pred_in):\n",
    "    batch_size = y_true_in.shape[0]\n",
    "    metric = []\n",
    "    for batch in range(batch_size):\n",
    "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
    "        metric.append(value)\n",
    "    return np.mean(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d1bd5d7ea1b37594e5b317136c5fe9a389ebc292",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thres = np.linspace(0.25, 0.75, 20)\n",
    "thres_ioc = [iou_metric_batch(y_valid, np.int32(preds_val > t)) for t in tqdm_notebook(thres)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c784a0d1f66bb70cd225bda563a4fce993822256",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(thres, thres_ioc);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "433af33f3fd34ae146ef74f7f7da00dbd15c51ce",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_thres = thres[np.argmax(thres_ioc)]\n",
    "best_thres, max(thres_ioc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "844cded40edc71652bc5b26852245e37f46f6448"
   },
   "source": [
    "# Prepare Submission\n",
    "We need to prepare the submission. A nice CSV with predictions. All of this is one to one from Ketil and does not differ from any of the other segmentation tasks. Check them out to improve on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "73336f76166028ba39c8164083c9564a0d5afe40",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def RLenc(img, order='F', format=True):\n",
    "    \"\"\"\n",
    "    img is binary mask image, shape (r,c)\n",
    "    order is down-then-right, i.e. Fortran\n",
    "    format determines if the order needs to be preformatted (according to submission rules) or not\n",
    "\n",
    "    returns run length as an array or string (if format is True)\n",
    "    \"\"\"\n",
    "    bytes = img.reshape(img.shape[0] * img.shape[1], order=order)\n",
    "    runs = []  ## list of run lengths\n",
    "    r = 0  ## the current run length\n",
    "    pos = 1  ## count starts from 1 per WK\n",
    "    for c in bytes:\n",
    "        if (c == 0):\n",
    "            if r != 0:\n",
    "                runs.append((pos, r))\n",
    "                pos += r\n",
    "                r = 0\n",
    "            pos += 1\n",
    "        else:\n",
    "            r += 1\n",
    "\n",
    "    # if last run is unsaved (i.e. data ends with 1)\n",
    "    if r != 0:\n",
    "        runs.append((pos, r))\n",
    "        pos += r\n",
    "        r = 0\n",
    "\n",
    "    if format:\n",
    "        z = ''\n",
    "\n",
    "        for rr in runs:\n",
    "            z += '{} {} '.format(rr[0], rr[1])\n",
    "        return z[:-1]\n",
    "    else:\n",
    "        return runs\n",
    "\n",
    "pred_dict = {id_[:-4]:RLenc(np.round(preds_test_upsampled[i] > best_thres)) for i,id_ in tqdm_notebook(enumerate(test_ids))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6eaf7acaf4a0678638c5e40732c6533816777637",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.DataFrame.from_dict(pred_dict,orient='index')\n",
    "sub.index.names = ['id']\n",
    "sub.columns = ['rle_mask']\n",
    "sub.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
