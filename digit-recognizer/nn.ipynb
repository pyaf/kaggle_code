{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "train, test = train_test_split(data, test_size=0.2,random_state=0, stratify=data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = train.loc[:, 'label'].as_matrix()\n",
    "Y_train = np.eye(10)[Y_train].T\n",
    "X_train = train.loc[:, train.columns != 'label'].as_matrix().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test = test.loc[:, 'label'].as_matrix()\n",
    "Y_test = np.eye(10)[Y_test].T\n",
    "X_test = test.loc[:, test.columns != 'label'].as_matrix().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.multiply(X_train, 1.0/255.0)\n",
    "X_test = np.multiply(X_test, 1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 33600) (10, 33600)\n",
      "(784, 8400) (10, 8400)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_next_batch(initial, batch_size, X, Y):\n",
    "    return X[:, initial:initial+batch_size], Y[:, initial:initial+batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Initializing parameters with `he initialization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def Initialize_parameters_deep(layer_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = {}\n",
    "    for l in range(1, len(layer_dims)):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * np.sqrt(2/layer_dims[l-1])\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    t = np.exp(Z)\n",
    "    return t / np.sum(t, axis=0)\n",
    "\n",
    "def relu(Z):\n",
    "    return np.maximum(0, Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Forward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    Z = np.dot(W, A_prev) + b\n",
    "    linear_cache = (A_prev, W, b)\n",
    "\n",
    "    if activation == 'softmax':\n",
    "        A = softmax(Z)\n",
    "    elif activation == 'relu':\n",
    "        A = relu(Z)\n",
    "        \n",
    "    activation_cache = Z\n",
    "    cache = (linear_cache, activation_cache)\n",
    "#     print('LAF', A.shape)\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def forward_propogation(X, parameters):\n",
    "    A_prev = X\n",
    "    L = len(parameters)//2\n",
    "    caches = []\n",
    "    for l in range(1, L):\n",
    "        Wl = parameters['W' + str(l)]\n",
    "        bl = parameters['b' + str(l)]\n",
    "        A_prev, cache = linear_activation_forward(A_prev, Wl, bl, 'relu')\n",
    "        caches.append(cache)\n",
    "\n",
    "    AL, cache = linear_activation_forward(A_prev, parameters['W' + str(L)], parameters['b' + str(L)], 'softmax')\n",
    "    caches.append(cache)\n",
    "    return AL, caches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Cost Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#np.mulliply is diff than X*Y\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = -1 / m * (np.sum(Y*np.log(AL)))\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost\n",
    "\n",
    "def compute_cost_with_regularization(AL, Y, parameters, lambd):\n",
    "    m = Y.shape[1]\n",
    "    cost = 0\n",
    "    for l in range(1, len(parameters)//2):\n",
    "        cost += np.sum(np.square(parameters['W' + str(l)]))\n",
    "\n",
    "    cross_entropy_cost = compute_cost(AL, Y)\n",
    "    L2_regularization_cost = lambd * cost / (2 * m)\n",
    "\n",
    "    return  cross_entropy_cost + L2_regularization_cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Backward Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def relu_backward(dA, activation_cache):\n",
    "    Z = activation_cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == 'softmax':\n",
    "        dZ = dA\n",
    "    elif activation == 'relu':\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        \n",
    "    A_prev, W, b = linear_cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = 1 / m * np.dot(dZ, A_prev.T)\n",
    "    db = 1 / m * np.sum(dZ, axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "\n",
    "    return dA_prev, dW, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def backward_propogation(AL, Y, caches):\n",
    "    L = len(caches)\n",
    "    grads = {}\n",
    "    dZ = AL - Y\n",
    "    grads['dA' + str(L)], grads['dW' + str(L)], grads['db' + str(L)] = linear_activation_backward(dZ, caches[L-1], 'softmax')\n",
    "    A_prev = AL\n",
    "    for l in range(L-1, 0, -1):\n",
    "        cache = caches[l-1]\n",
    "        dA = grads['dA' + str(l+1)]\n",
    "        dA_prev, dW, db = linear_activation_backward(dA, cache, 'relu')\n",
    "        grads['dA' + str(l)] = dA_prev\n",
    "        grads['dW' + str(l)] = dW\n",
    "        grads['db' + str(l)] = db\n",
    "        \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def backward_propogation_with_regularization(AL, Y, caches, lambd):\n",
    "    L = len(caches)\n",
    "    grads = {}\n",
    "    m = Y.shape[1]\n",
    "    dZ = AL - Y\n",
    "    grads['dA' + str(L)], grads['dW' + str(L)], grads['db' + str(L)] = linear_activation_backward(dZ, caches[L-1], 'softmax')\n",
    "    grads['dW' + str(L)] += (lambd * caches[L-1][0][1]) / m\n",
    "    A_prev = AL\n",
    "\n",
    "    for l in range(L-1, 0, -1):\n",
    "        cache = caches[l-1]\n",
    "        dA = grads['dA' + str(l+1)]\n",
    "        dA_prev, dW, db = linear_activation_backward(dA, cache, 'relu')\n",
    "        grads['dA' + str(l)] = dA_prev\n",
    "        grads['dW' + str(l)] = dW + (lambd * cache[0][1]) / m\n",
    "        grads['db' + str(l)] = db\n",
    "        \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Updating parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    for l in range(1, len(parameters)//2 + 1 ):\n",
    "        parameters['W' + str(l)] -= learning_rate * grads['dW' + str(l)]\n",
    "        parameters['b' + str(l)] -= learning_rate * grads['db' + str(l)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def the_model(X_train, Y_train, layers_dims, learning_rate, num_iterations, lambd):\n",
    "    costs = []\n",
    "    initial = 0\n",
    "    batch_size = 1000\n",
    "    parameters = Initialize_parameters_deep(layers_dims)\n",
    "\n",
    "    for i in range(num_iterations+1):\n",
    "        X, Y = get_next_batch(initial, batch_size, X_train, Y_train)\n",
    "#         print(initial, X.shape, Y.shape)\n",
    "        initial = 0 if initial>=33000 else initial+batch_size\n",
    "#         print(initial)\n",
    "        AL, caches = forward_propogation(X, parameters)\n",
    "        if lambd == 0:\n",
    "            cost = compute_cost(AL, Y)\n",
    "            grads = backward_propogation(AL, Y, caches)\n",
    "        else:\n",
    "            cost = compute_cost_with_regularization(AL, Y, parameters, lambd)\n",
    "            grads = backward_propogation_with_regularization(AL, Y, caches, lambd)\n",
    "            \n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        if (i%500==0):\n",
    "            print('Cost at iteration %s is %s' %(i, cost))\n",
    "\n",
    "        costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per 10000)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    np.save(\"parameters\", parameters)\n",
    "    return parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at iteration 0 is 2.38761195804\n",
      "Cost at iteration 500 is 0.0552477180694\n",
      "Cost at iteration 1000 is 0.0221190483416\n",
      "Cost at iteration 1500 is 0.00923716052476\n",
      "Cost at iteration 2000 is 0.00684658077162\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBRERSVAoiIhIwv8HNBTaTvCiUcoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b6c80cb6828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 3s, sys: 38min 44s, total: 44min 48s\n",
      "Wall time: 1min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "layers_dims = [784, 128, 64, 10]\n",
    "learning_rate = 0.5\n",
    "num_iterations = 2001\n",
    "lambd = 0\n",
    "parameters = the_model(X_train, Y_train, layers_dims, learning_rate, num_iterations, lambd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(X, Y, parameters):\n",
    "    Y_hat, _ = forward_propogation(X, parameters)\n",
    "    m = Y.shape[1]\n",
    "    acc = np.sum(np.argmax(Y, axis=0) == np.argmax(Y_hat, axis=0)) / m\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 191 ms, sys: 102 ms, total: 293 ms\n",
      "Wall time: 310 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.99970238095238095"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "accuracy(X_train, Y_train, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 ms, sys: 21.3 ms, total: 32.3 ms\n",
      "Wall time: 70.9 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96857142857142853"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "accuracy(X_test, Y_test, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_data = pd.read_csv('test.csv')\n",
    "X_test_data = np.multiply(X_test_data, 1.0/255.0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done Writing\n"
     ]
    }
   ],
   "source": [
    "Y, _ = forward_propogation(X_test_data, parameters)\n",
    "Y = np.argmax(Y, axis=0)\n",
    "with open('submission-nn-v1.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['ImageId', 'Label'])\n",
    "    for i in range(Y.shape[0]):\n",
    "        writer.writerow([i+1, Y[i]])\n",
    "\n",
    "print(\"Done Writing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:ML]",
   "language": "python",
   "name": "conda-env-ML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
